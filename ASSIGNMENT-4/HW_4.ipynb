{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhnq4YzdybKY"
      },
      "source": [
        "**Question 1 [ 40 Points ] - Support Vector Machines (SVMs)** \n",
        "\n",
        "[25 points ] Download this dataset, split it as a 80% training and 20% test set. and implement the support vector algorithm from scratch using Numpy and Pandas.\n",
        "\n",
        "[10 points ] Report the accuracies for the train and test sets. Comment on whether your model has overfit.\n",
        "\n",
        "[5 points] Test your model performance with the scikit-learn model. Comment on the difference in accuracy. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: numpy in /home/z/.local/lib/python3.11/site-packages (1.23.4)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: sklearn in /home/z/.local/lib/python3.11/site-packages (0.0.post1)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pandas in /home/z/.local/lib/python3.11/site-packages (1.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/z/.local/lib/python3.11/site-packages (from pandas) (2022.6)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /home/z/.local/lib/python3.11/site-packages (from pandas) (1.23.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install numpy\n",
        "! pip install sklearn\n",
        "! pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     sepal length  sepal width  petal length  petal width           label  \\\n",
            "0             5.1          3.5           1.4          0.2     Iris-setosa   \n",
            "1             4.9          3.0           1.4          0.2     Iris-setosa   \n",
            "2             4.7          3.2           1.3          0.2     Iris-setosa   \n",
            "3             4.6          3.1           1.5          0.2     Iris-setosa   \n",
            "4             5.0          3.6           1.4          0.2     Iris-setosa   \n",
            "..            ...          ...           ...          ...             ...   \n",
            "145           6.7          3.0           5.2          2.3  Iris-virginica   \n",
            "146           6.3          2.5           5.0          1.9  Iris-virginica   \n",
            "147           6.5          3.0           5.2          2.0  Iris-virginica   \n",
            "148           6.2          3.4           5.4          2.3  Iris-virginica   \n",
            "149           5.9          3.0           5.1          1.8  Iris-virginica   \n",
            "\n",
            "     converted  \n",
            "0            0  \n",
            "1            0  \n",
            "2            0  \n",
            "3            0  \n",
            "4            0  \n",
            "..         ...  \n",
            "145          2  \n",
            "146          2  \n",
            "147          2  \n",
            "148          2  \n",
            "149          2  \n",
            "\n",
            "[150 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "columns = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\", \"label\"]\n",
        "df = pd.read_csv('./iris.data', names=columns)\n",
        "\n",
        "converted = []\n",
        "for i in range(len(df['label'])):\n",
        "    if df['label'][i] == \"Iris-setosa\":\n",
        "        converted.append(0)\n",
        "    elif df['label'][i] == \"Iris-versicolor\":\n",
        "        converted.append(1)\n",
        "    else:\n",
        "        converted.append(2)\n",
        "df['converted'] = converted\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "I49gdoFFyR7D"
      },
      "outputs": [],
      "source": [
        "class SVM:\n",
        "\n",
        "    def __init__(self, number_of_iterations=1000, lamb=0.001, alpha=0.01, c = 1, main_class=0):\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "        self.alpha = alpha\n",
        "        self.number_of_iterations = number_of_iterations\n",
        "        self.lambda_param = lamb\n",
        "        self.c = c\n",
        "        self.main_class = main_class\n",
        "\n",
        "    def convert(self, y):\n",
        "        y_new = [0] * len(y)\n",
        "        for i in range(len(y)):\n",
        "            if y[i] != self.main_class:\n",
        "                y_new[i] = -1\n",
        "            elif y[i] == self.main_class:\n",
        "                y_new[i] = 1\n",
        "        \n",
        "        return y_new\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        converted_y = self.convert(y)\n",
        "\n",
        "\n",
        "        for _ in range(self.number_of_iterations):\n",
        "            for i in range(len(X)):\n",
        "                condition = converted_y[i] * \\\n",
        "                    (np.dot(X[i], self.weights) - self.bias) >= self.c\n",
        "                if condition:\n",
        "                    self.weights -= self.alpha * \\\n",
        "                        (2 * self.lambda_param * self.weights)\n",
        "                else:\n",
        "                    self.weights -= self.alpha * \\\n",
        "                        (2 * self.lambda_param *\n",
        "                         self.weights - np.dot(X[i], converted_y[i]))\n",
        "                    self.bias -= self.alpha * converted_y[i]\n",
        "\n",
        "    def predict(self, X):\n",
        "        ans = []\n",
        "        estimate = np.dot(X, self.weights) - self.bias\n",
        "        for i in estimate:\n",
        "            if np.sign(i)<0:\n",
        "                if self.main_class == 0:\n",
        "                    ans.append(1)\n",
        "                elif self.main_class == 1:\n",
        "                    ans.append(2)\n",
        "                elif self.main_class == 2:\n",
        "                    ans.append(0)\n",
        "            else: \n",
        "                ans.append(self.main_class)\n",
        "        \n",
        "        return ans\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length</th>\n",
              "      <th>sepal width</th>\n",
              "      <th>petal length</th>\n",
              "      <th>petal width</th>\n",
              "      <th>label</th>\n",
              "      <th>converted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length  sepal width  petal length  petal width        label  \\\n",
              "0           5.1          3.5           1.4          0.2  Iris-setosa   \n",
              "1           4.9          3.0           1.4          0.2  Iris-setosa   \n",
              "2           4.7          3.2           1.3          0.2  Iris-setosa   \n",
              "3           4.6          3.1           1.5          0.2  Iris-setosa   \n",
              "4           5.0          3.6           1.4          0.2  Iris-setosa   \n",
              "\n",
              "   converted  \n",
              "0          0  \n",
              "1          0  \n",
              "2          0  \n",
              "3          0  \n",
              "4          0  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [5.  3.  1.6 0.2]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.9 3.  4.2 1.5]\n",
            " [6.  2.2 4.  1. ]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.6 3.  4.1 1.3]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.  2.2 5.  1.5]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [5.9 3.  5.1 1.8]] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = np.array(df.iloc[:,0:4])\n",
        "y = np.array(df['converted'])\n",
        "print(X, y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "INzXYmZWzrFg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "# Model iris-setosa => 0\n",
        "model = SVM(number_of_iterations=1000, lamb=0.001, alpha=0.01, c = 1, main_class=0)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred_0 = model.predict(X_test)\n",
        "print(y_pred_0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "# Model iris-versicolor => 1\n",
        "model = SVM(number_of_iterations=1000, lamb=0.001, alpha=0.01, c = 1, main_class=1)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred_1 = model.predict(X_test)\n",
        "print(y_pred_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "# Model iris-virginica => 2\n",
        "model = SVM(number_of_iterations=1000, lamb=0.001, alpha=0.01, c = 1, main_class=2)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred_2 = model.predict(X_test)\n",
        "print(y_pred_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "final_predictions = []\n",
        "for i in range(len(y_pred_0)):\n",
        "    map = {0:0, 1:0, 2:0}\n",
        "    map[y_pred_0[i]] += 1\n",
        "    map[y_pred_1[i]] += 1\n",
        "    map[y_pred_2[i]] += 1\n",
        "\n",
        "    m = max(map.values())\n",
        "    if map[0] == m:\n",
        "        final_predictions.append(0)\n",
        "    elif map[1] == m:\n",
        "        final_predictions.append(1)\n",
        "    else:\n",
        "        final_predictions.append(2)\n",
        "    \n",
        "\n",
        "print(final_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1]\n"
          ]
        }
      ],
      "source": [
        "# Model iris-setosa => 0\n",
        "model = SVM(number_of_iterations=1000, lamb=0.001, alpha=0.01, c = 1, main_class=0)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred_0 = model.predict(X_train)\n",
        "print(y_pred_0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1]\n"
          ]
        }
      ],
      "source": [
        "# Model iris-versicolor => 1\n",
        "model = SVM(number_of_iterations=1000, lamb=0.001, alpha=0.01, c = 1, main_class=1)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred_1 = model.predict(X_train)\n",
        "print(y_pred_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "# Model iris-virginica => 2\n",
        "model = SVM(number_of_iterations=1000, lamb=0.001, alpha=0.01, c = 1, main_class=2)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred_2 = model.predict(X_train)\n",
        "print(y_pred_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 2, 1, 0, 1, 0, 1, 1, 1, 2, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 2, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 2, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 2, 1, 1, 0, 2, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1]\n"
          ]
        }
      ],
      "source": [
        "final_predictions2 = []\n",
        "for i in range(len(y_pred_0)):\n",
        "    map = {0:0, 1:0, 2:0}\n",
        "    map[y_pred_0[i]] += 1\n",
        "    map[y_pred_1[i]] += 1\n",
        "    map[y_pred_2[i]] += 1\n",
        "\n",
        "    m = max(map.values())\n",
        "    if map[0] == m:\n",
        "        final_predictions2.append(0)\n",
        "    elif map[1] == m:\n",
        "        final_predictions2.append(1)\n",
        "    else:\n",
        "        final_predictions2.append(2)\n",
        "    \n",
        "\n",
        "print(final_predictions2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "My SVM Train data accuracy is : 0.7\n",
            "My SVM  Test data accuracy is : 0.7333333333333333\n",
            "The model is not overfitted\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"My SVM Train data accuracy is :\", accuracy_score(final_predictions2, y_train))\n",
        "print(\"My SVM  Test data accuracy is :\", accuracy_score(final_predictions, y_test))\n",
        "print(\"The model is not overfitted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SKLearn SVM Test data accuracy is : 0.9666666666666667\n",
            "SKLearn SVM  Train data accuracy is : 0.95\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'\\nThe difference in the accuracy could be because of the OVR (one-versus-rest) approach\\ntaken by me and Sklearn internal classifier handled multi class data differently\\nIt is also possible that the learning rate and number of iterations might be different\\ndue to which the accuracy is different\\n'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn import svm\n",
        "\n",
        "model = svm.SVC(C=1.0)\n",
        "model.fit(X_train, y_train)\n",
        "test_predictions = model.predict(X_test)\n",
        "train_predictions = model.predict(X_train)\n",
        "\n",
        "print(\"SKLearn SVM Test data accuracy is :\", accuracy_score(test_predictions, y_test))\n",
        "print(\"SKLearn SVM  Train data accuracy is :\", accuracy_score(train_predictions, y_train))\n",
        "\n",
        "\"\"\"\n",
        "The difference in the accuracy could be because of the OVR (one-versus-rest) approach\n",
        "taken by me and Sklearn internal classifier handled multi class data differently\n",
        "It is also possible that the learning rate and number of iterations might be different\n",
        "due to which the accuracy is different\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcdbdv0Sz3Xz"
      },
      "source": [
        "Training accuracy : 0.7\n",
        "\n",
        "Test accuracy : 0.733"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES4uUFwXz-aX"
      },
      "source": [
        "**Question 2 [ 40 Points ] - Decision Trees** \n",
        "\n",
        "a. [5 points] Complete the test_split function.\n",
        "\n",
        "b. [5 points] Complete the gini_index function.\n",
        "\n",
        "c. [5 points] Complete the get_split function.\n",
        "\n",
        "d. [15 points] Complete the split function.\n",
        "\n",
        "e. [10 points] Print the tree. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "kDRZCShz45P3"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "FqI3dUn-z95m"
      },
      "outputs": [],
      "source": [
        "def test_split(index, value, dataset):\n",
        "    left, right = list(), list()\n",
        "    for row in dataset:\n",
        "        if row[index] < value:\n",
        "            left.append(row)\n",
        "        else:\n",
        "            right.append(row)\n",
        "    return left, right\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "q338FeZs0p51"
      },
      "outputs": [],
      "source": [
        "def gini_index(groups, classes):\n",
        "    # count all samples at split point\n",
        "    n_instances = float(sum([len(group) for group in groups]))\n",
        "    # sum weighted Gini index for each group\n",
        "    gini = 0.0\n",
        "    \n",
        "    for group in groups:\n",
        "        try:\n",
        "            count = 0\n",
        "\n",
        "            for class_label in classes:\n",
        "                class_label_count = 0\n",
        "            \n",
        "                for i in group:\n",
        "                    if i[-1] == class_label:\n",
        "                        class_label_count += 1\n",
        "                count += (class_label_count / len(group)) ** 2\n",
        "\n",
        "            gini += (1 - count) * (len(group) / n_instances)\n",
        "        except ZeroDivisionError:\n",
        "            continue\n",
        "    return gini\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "PL6EsIaM05EJ"
      },
      "outputs": [],
      "source": [
        "# Select the best split point for a dataset\n",
        "def get_split(dataset):\n",
        "    class_values = list(set(row[-1] for row in dataset))\n",
        "    b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
        "    \n",
        "    for index in range(len(dataset[0])-1):\n",
        "        for row in dataset:\n",
        "            # Hint : Call the test_split function here.\n",
        "            groups = test_split(index, row[index], dataset)\n",
        "            # Hint : Call the gini_index function here.\n",
        "            gini = gini_index(groups, class_values)\n",
        "            if gini < b_score:\n",
        "                b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
        "    return {'index': b_index, 'value': b_value, 'groups': b_groups}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "cb_s3CsC1aGV"
      },
      "outputs": [],
      "source": [
        "# Create a terminal node value\n",
        "def to_terminal(group):\n",
        "\toutcomes = [row[-1] for row in group]\n",
        "\treturn max(set(outcomes), key=outcomes.count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0Fv9McfA1cuP"
      },
      "outputs": [],
      "source": [
        "# Create child splits for a node or make terminal\n",
        "#Hint : Just call the to_terminal and get_split functions defined above. \n",
        "\n",
        "def split(node, max_depth, min_size, depth):\n",
        "    left, right = node['groups']\n",
        "    del (node['groups'])\n",
        "\n",
        "    # check for a no split\n",
        "    if not left or not right:\n",
        "        node['left'] = node['right'] = to_terminal(left + right)\n",
        "        return\n",
        "\n",
        "    # check for max depth\n",
        "    if depth >= max_depth:\n",
        "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
        "        return\n",
        "\n",
        "    # process left child\n",
        "    if len(left) <= min_size:\n",
        "        node['left'] = to_terminal(left)\n",
        "    else:\n",
        "        node['left'] = get_split(left)\n",
        "        split(node['left'], max_depth, min_size, depth+1)\n",
        "    \n",
        "    # process right child\n",
        "    if len(right) <= min_size:\n",
        "        node['right'] = to_terminal(right)\n",
        "    else:\n",
        "        node['right'] = get_split(right)\n",
        "        split(node['right'], max_depth, min_size, depth+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "KQiNy9NE2IoJ"
      },
      "outputs": [],
      "source": [
        "def build_tree(train, max_depth, min_size):\n",
        "    root = get_split(train)\n",
        "    split(root, max_depth, min_size, 1)\n",
        "    return root"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "rSYBf-DQ2LYs"
      },
      "outputs": [],
      "source": [
        "def print_tree(node, depth=0):\n",
        "    if isinstance(node, dict):\n",
        "        print('%s[X%d < %.3f]' %\n",
        "              ((depth*' ', (node['index']+1), node['value'])))\n",
        "        print_tree(node['left'], depth+1)\n",
        "        print_tree(node['right'], depth+1)\n",
        "    else:\n",
        "        print('%s[%s]' % ((depth*' ', node)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "MkuT-7SY40Yu"
      },
      "outputs": [],
      "source": [
        "iris= load_iris()\n",
        "\n",
        "X= np.array(iris.data)\n",
        "y= np.array(iris.target).reshape(-1,1)\n",
        "\n",
        "data = np.append(X,y,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "42ivIbmh2j5Y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[X3 < 3.000]\n",
            " [0.0]\n",
            " [1.0]\n"
          ]
        }
      ],
      "source": [
        "tree = build_tree(data, 1, 1)\n",
        "print_tree(tree)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAEFoJMP70So"
      },
      "source": [
        "**Question 3 [ 20 Points ] - Random Forests and Boosting**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "U1feyKIo73h5"
      },
      "outputs": [],
      "source": [
        "col_names = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
        "\n",
        "df = pd.read_csv('./car.data', names=col_names)\n",
        "\n",
        "X = df.drop(['class'], axis=1)\n",
        "y = df['class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: category-encoders in /home/z/.local/lib/python3.11/site-packages (2.5.1.post0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /home/z/.local/lib/python3.11/site-packages (from category-encoders) (1.23.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /home/z/.local/lib/python3.11/site-packages (from category-encoders) (1.1.3)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /home/z/.local/lib/python3.11/site-packages (from category-encoders) (1.9.3)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /home/z/.local/lib/python3.11/site-packages (from category-encoders) (0.13.5)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /home/z/.local/lib/python3.11/site-packages (from category-encoders) (1.5.1)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /home/z/.local/lib/python3.11/site-packages (from category-encoders) (0.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/lib/python3.11/site-packages (from pandas>=1.0.5->category-encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/z/.local/lib/python3.11/site-packages (from pandas>=1.0.5->category-encoders) (2022.6)\n",
            "Requirement already satisfied: six in /usr/lib/python3.11/site-packages (from patsy>=0.5.1->category-encoders) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /home/z/.local/lib/python3.11/site-packages (from scikit-learn>=0.20.0->category-encoders) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/z/.local/lib/python3.11/site-packages (from scikit-learn>=0.20.0->category-encoders) (3.1.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/lib/python3.11/site-packages (from statsmodels>=0.9.0->category-encoders) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/lib/python3.11/site-packages (from packaging>=21.3->statsmodels>=0.9.0->category-encoders) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "! pip install category-encoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "import category_encoders\n",
        "\n",
        "# We need to convert the strings into numbers\n",
        "encoder = category_encoders.OrdinalEncoder(cols = col_names[:len(col_names) - 1])\n",
        "X_train, X_test = encoder.fit_transform(X_train), encoder.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "classifier = RandomForestClassifier(random_state=0)\n",
        "classifier.fit(X_train, y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred_train = classifier.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy is : 1.0\n",
            "Test Accuracy is : 0.9457092819614711\n"
          ]
        }
      ],
      "source": [
        "print('Train Accuracy is :', accuracy_score(y_train, y_pred_train))\n",
        "print('Test Accuracy is :', accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gradient_boost_classifier = GradientBoostingClassifier()\n",
        "gradient_boost_classifier.fit(X_train, y_train)\n",
        "y_pred = gradient_boost_classifier.predict(X_test)\n",
        "y_pred_train = gradient_boost_classifier.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy is : 0.9913569576490925\n",
            "Test Accuracy is : 0.968476357267951\n"
          ]
        }
      ],
      "source": [
        "print('Train Accuracy is :', accuracy_score(y_train, y_pred_train))\n",
        "print('Test Accuracy is :', accuracy_score(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
